{
"model_name_or_path": "t5-small",
"tokenizer_name": "t5-small",
"learning_rate": 1e-2,
"output_dir": "outputs/test3/",
"max_source_length": 128,
"max_target_length": 128 ,
"val_max_target_length":128,
"test_max_target_length":128,
"num_train_epochs": 3,
"warmup_steps": 500,
"eval_steps": 200,
"overwrite_output_dir": true,
"tasks": ["scitail", "imdb", "snli", "trec", "yelp_polarity", "social_i_qa", "cosmos_qa", "winogrande", "hellaswag", "commonsense_qa"],
"eval_tasks": ["scitail", "imdb", "snli", "trec", "yelp_polarity", "social_i_qa", "cosmos_qa", "winogrande", "hellaswag", "commonsense_qa"],
"sampling": true,
"label_smoothing": 0.1,
"freeze_encoder":false,
"freeze_embeds":false,
"per_device_train_batch_size":64,
"per_device_eval_batch_size":64,
"save_steps": 200,
"logging_first_step":true,
"logging_steps": 200,
"save_total_limit": 1,
"train_adapters": true,
"adapter_config_name":"parametric-meta-adapter",
"temperature": 10,
"do_eval": true,
"predict_with_generate": true,
"task_embedding_dir":"test_data/task_embeddings/n-train-100",
"task_embedding_dim": 512,
"do_train": false,
"n_train": 10,
"n_val": 10,
"reduction_factor": 16,
"non_linearity": "relu",
"projected_task_embedding_dim": 512,
"add_adapters_in_decoder": true,
"unfreeze_lm_head": false,
"unfreeze_layer_norms": true,
"train_task_embeddings": true,
"hidden_dim": 256,
"add_adapter_in_feed_forward": true,
"add_adapter_in_self_attention": false,
"conditional_layer_norm": true
}



