{
"model_name_or_path": "t5-base",
"tokenizer_name": "t5-base",
"learning_rate": 3e-4,
"output_dir": "/workdir/seq2seq/outputs/fixed_length_emb/t5-base-attentive",
"max_source_length": 128,
"max_target_length": 128 ,
"val_max_target_length":128,
"test_max_target_length":128,
"do_train": true,
"num_train_epochs": 20,
"warmup_steps": 500,
"eval_steps": 500,
"overwrite_output_dir": true,
"task": ["scitail", "mrpc"],
"sampling": true,
"label_smoothing": 0.1,
"fixed_length_emb": true,
"encoder_pooling": "attentive",
"tpu_num_cores": 0,
"prediction_loss_only": true,
"freeze_encoder":false,
"freeze_embeds":false,
"per_device_train_batch_size":8,
"per_device_eval_batch_size":8,
"save_steps": 500,
"logging_first_step":true,
"logging_steps": 200
}





